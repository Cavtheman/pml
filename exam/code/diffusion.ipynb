{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import einops as ein\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(n_channels // 4, n_channels)\n",
    "        self.act = nn.Mish()\n",
    "        self.lin2 = nn.Linear(n_channels, n_channels)\n",
    "        half_dim = n_channels // 8\n",
    "        emb_scale = np.log(10000) / (half_dim - 1)\n",
    "        self.emb = torch.exp(torch.arange(half_dim) * -emb_scale)[None, :]\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = t[:, None] * self.emb.to(t.device)\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        emb = self.act(self.lin1(emb))\n",
    "        emb = self.lin2(emb)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_channels):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            nn.GroupNorm(32, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
    "            nn.GroupNorm(32, out_channels),\n",
    "            nn.Mish(),\n",
    "        )\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.time_emb = nn.Linear(time_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        h = self.block1(x)\n",
    "        h += self.time_emb(t)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "        return h + self.shortcut(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, time_channels, chs):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList(\n",
    "            [Block(chs[i], chs[i + 1], time_channels)\n",
    "             for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x, t)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, time_channels, chs):\n",
    "        super().__init__()\n",
    "        self.upconvs = nn.ModuleList()\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "        for in_channels, out_channels in zip(chs[:-1], chs[1:]):\n",
    "            self.upconvs.append(nn.ConvTranspose2d(\n",
    "                in_channels, out_channels, 2, 2))\n",
    "            self.dec_blocks.append(\n",
    "                Block(in_channels, out_channels, time_channels))\n",
    "\n",
    "    def forward(self, x, t, encoder_features):\n",
    "        for upconv, dec_block, enc_ftrs in zip(\n",
    "            self.upconvs, self.dec_blocks, encoder_features\n",
    "        ):\n",
    "            x = upconv(x)\n",
    "            enc_ftrs = nn.functional.interpolate(\n",
    "                enc_ftrs, size=x.shape[2:], mode=\"bilinear\", align_corners=True\n",
    "            )\n",
    "            x = torch.cat([x, enc_ftrs], dim=1)\n",
    "            x = dec_block(x, t)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, image_channels, n_channels):\n",
    "        super().__init__()\n",
    "        time_channels = n_channels * 4\n",
    "        self.image_proj = nn.Conv2d(image_channels, n_channels, 3, 1, 1)\n",
    "        self.time_emb = TimeEmbedding(time_channels)\n",
    "        self.encoder = Encoder(time_channels, (32, 64, 128, 256, 512, 1024))\n",
    "        self.decoder = Decoder(time_channels, (1024, 512, 256, 128, 64))\n",
    "        self.final = nn.Conv2d(64, 1, 3, 1, 1)\n",
    "        self.act = nn.Mish()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.image_proj(x)\n",
    "        time = self.time_emb(t)\n",
    "        enc_ftrs = self.encoder(x, time)\n",
    "        out = self.decoder(enc_ftrs[::-1][0], time, enc_ftrs[::-1][1:])\n",
    "        return self.final(self.act(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, noise_steps=1000, device=\"cpu\"):\n",
    "        super(Diffusion, self).__init__()\n",
    "        self.beta = torch.linspace(1e-4, 0.02, noise_steps, device=device)\n",
    "        self.alpha = 1 - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.T = noise_steps\n",
    "        self.eps_model = UNet(image_channels=1, n_channels=32)\n",
    "        self.device = device\n",
    "\n",
    "    def q(self, x0, t):\n",
    "        temp = ein.rearrange(self.alpha_bar[t], \"b -> b () () ()\")\n",
    "        mean = torch.sqrt(temp) * x0\n",
    "        var = 1 - temp\n",
    "        return mean, var\n",
    "\n",
    "    def sample_q(self, x0, t, epsilon=None):\n",
    "        if epsilon is None:\n",
    "            epsilon = torch.randn_like(x0)\n",
    "\n",
    "        mean, var = self.q(x0, t)\n",
    "        return mean + torch.sqrt(var) * epsilon\n",
    "\n",
    "    def p_sample(self, xt, t):\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        alpha_bar = ein.rearrange(self.alpha_bar[t], \"b -> b () () ()\")\n",
    "        alpha = ein.rearrange(self.alpha[t], \"b -> b () () ()\")\n",
    "        eps_coef = (1 - alpha) / torch.sqrt((1 - alpha_bar))\n",
    "        mean = (1 / torch.sqrt(alpha)) * (xt - eps_coef * eps_theta)\n",
    "        var = self.beta[t]\n",
    "        epsilon = torch.randn(xt.shape, device=xt.device)\n",
    "        return (mean + torch.sqrt(var) * epsilon).detach()\n",
    "\n",
    "    def loss(self, x0, noise=None):\n",
    "        t = torch.randint(0, self.T, (x0.size(0),),\n",
    "                          device=x0.device, dtype=torch.long)\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x0)\n",
    "        xt = self.sample_q(x0, t, noise)\n",
    "        eps_theta = self.eps_model(xt, t)\n",
    "        return F.mse_loss(noise, eps_theta)\n",
    "\n",
    "    def show_image(self, img, title=\"\"):\n",
    "        img = img.cpu().detach().numpy()\n",
    "        plt.imshow(img[0, 0, :, :], cmap=\"gray\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def _sample_x0(self, xt: torch.Tensor, n_steps: int):\n",
    "        n_samples = xt.shape[0]\n",
    "        for t_ in range(n_steps):\n",
    "            t = n_steps - t_ - 1\n",
    "            xt = self.p_sample(xt, xt.new_full(\n",
    "                (n_samples,), t, dtype=torch.long))\n",
    "        return xt\n",
    "\n",
    "    def sample(self, n_steps: int):\n",
    "        xt = torch.randn([1, 1, 32, 32], device=self.device)\n",
    "        x0 = self._sample_x0(xt, n_steps)\n",
    "        self.show_image(x0, title=\"Sampled image\")\n",
    "        return x0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Diffusion(device=device).to(device)\n",
    "optimizer = optim.RAdam(model.parameters(), lr=4e-5)\n",
    "\n",
    "batch_size = 128\n",
    "# Get train and test data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\", train=True, download=True, transform=transforms.ToTensor()\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"../data\", train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Make images 32x32\n",
    "def pad_image(img):\n",
    "    img = F.pad(img, (2, 2, 2, 2))\n",
    "    return img\n",
    "\n",
    "\n",
    "train_loader.dataset.transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), pad_image])\n",
    "\n",
    "test_loader.dataset.transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), pad_image])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(data)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(\n",
    "        \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
    "            epoch,\n",
    "            batch_idx * len(data),\n",
    "            len(train_loader.dataset),\n",
    "            100.0 * batch_idx / len(train_loader),\n",
    "            loss.item() / len(data),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.train()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            loss = model.loss(data)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\"====> Test set loss: {:.4f}\".format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"diffusion.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "name": "diffusion.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
