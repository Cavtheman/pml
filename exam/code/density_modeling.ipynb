{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import einops as ein\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CONV_VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(CONV_VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc21 = nn.Linear(128*3*3, latent_dim)\n",
    "        self.fc22 = nn.Linear(128*3*3, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128*3*3), \n",
    "            nn.ReLU(),\n",
    "            Rearrange (\"batch (a b c) -> batch a b c\", a=128, b=3, c=3),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, output_padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.fc21(x), self.fc22(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, lantent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(1, 32, 4, 2, 1)\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc1a = nn.Linear(400, 100)\n",
    "        self.fc21 = nn.Linear(100, lantent_dim) # Latent space of 2D\n",
    "        self.fc22 = nn.Linear(100, lantent_dim) # Latent space of 2D\n",
    "        self.fc3 = nn.Linear(lantent_dim, 100) # Latent space of 2D\n",
    "        self.fc3a = nn.Linear(100, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc1a(h1))\n",
    "        return self.fc21(h2), self.fc22(h2)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.relu(self.fc3a(h3))\n",
    "        return torch.sigmoid(self.fc4(h4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CONV_VAE(2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "batch_size2 = 256\n",
    "log_interval2 = 10\n",
    "epochs2 = 10\n",
    "\n",
    "#torch.manual_seed(1) # args.seed\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if device == \"cuda\" else {} # args.cuda\n",
    "\n",
    "# Get train and train data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size2, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size2, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train() # so that everything has gradients and we can do backprop and so on...\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad() # \"reset\" gradients to 0 for text iteration\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = model.loss(recon_batch, data, mu, logvar)\n",
    "        loss.backward() # calc gradients\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step() # backpropagation\n",
    "    train_losses.append(train_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad(): # no_grad turns of gradients...\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 20\n",
    "a = torch.linspace(-8., 8.,  num_rows)\n",
    "x_t = a.repeat(num_rows)\n",
    "x_t = x_t.view(num_rows,num_rows)\n",
    "y_t = x_t.t().flip(0)\n",
    "art_nums = torch.stack((x_t, y_t)).view(2,-1).t().to(device)\n",
    "print (art_nums.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs2 + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    if model.latent_dim == 2:\n",
    "        with torch.no_grad():\n",
    "            sample = model.decode(art_nums).cpu()\n",
    "            save_image(sample.view(-1, 1, 28, 28),\n",
    "                       'results-lin-lin/sample_' + str(epoch) + '.png', nrow=num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_loss(latent_dims):\n",
    "  global model\n",
    "  global optimizer\n",
    "  global train_losses\n",
    "  global test_losses\n",
    "  train_losses = []\n",
    "  test_losses = []\n",
    "  train_res = []\n",
    "  test_res = []\n",
    "\n",
    "  for l in latent_dims:\n",
    "    model = VAE(l).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    for epoch in range(1, 101):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "    train_res.append(train_losses)\n",
    "    test_res.append(test_losses)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "  for i, train_loss in enumerate(train_res):\n",
    "    f1 = open(f\"{latent_dims[i]}test.txt\", \"w\")\n",
    "    f1.write(f\"{test_res[i]}\")\n",
    "    f2 = open(f\"{latent_dims[i]}train.txt\", \"w\")\n",
    "    f2.write(f\"{train_loss}\")\n",
    "\n",
    "display_loss([2,4,8,16,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_array(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        array = f.read()\n",
    "    array = array.replace('[', '')\n",
    "    array = array.replace(']', '')\n",
    "    array = array.replace(' ', '')\n",
    "    array = array.split(',')\n",
    "    array = [float(i) for i in array]\n",
    "\n",
    "    # Remove first element for better visualization\n",
    "    array = array[1:]\n",
    "\n",
    "    return array\n",
    "\n",
    "folder1 = 'results-lin/'\n",
    "folder2 = 'results-conv/'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax1.plot(read_array(folder1 + '2test.txt'), label='linear 2')\n",
    "ax1.plot(read_array(folder2 + '2test.txt'), label='conv 2')\n",
    "ax1.plot(read_array(folder1 + '4test.txt'), label='linear 4')\n",
    "ax1.plot(read_array(folder2 + '4test.txt'), label='conv 4')\n",
    "ax1.set_title('Latent dimension 2 and 4')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Test loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(read_array(folder1 + '8test.txt'), label='linear 8')\n",
    "ax2.plot(read_array(folder2 + '8test.txt'), label='conv 8')\n",
    "ax2.plot(read_array(folder1 + '16test.txt'), label='linear 16')\n",
    "ax2.plot(read_array(folder2 + '16test.txt'), label='conv 16')\n",
    "ax2.set_title('Latent dimension 8 and 16')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Test loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torch.load('models/conv_vae16.pth', map_location=device)\n",
    "model_lin = torch.load('models/lin_vae16.pth', map_location=device)\n",
    "\n",
    "# Visualize reconstructions of five images from the test set\n",
    "with torch.no_grad():\n",
    "    sample = next(iter(test_loader))[0].to(device)\n",
    "    recon_lin, _, _ = model_lin(sample.view(-1, 784))\n",
    "    recon_conv, _, _ = model_conv(sample)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(10, 6))\n",
    "    for i in range(5):\n",
    "        axs[0, i].imshow(sample[i].cpu().view(28, 28), cmap='gray')\n",
    "        axs[1, i].imshow(recon_lin[i].cpu().view(28, 28), cmap='gray')\n",
    "        axs[2, i].imshow(recon_conv[i].cpu().view(28, 28), cmap='gray')\n",
    "\n",
    "    axs[0, 0].set_ylabel('Original', fontsize=16)\n",
    "    axs[1, 0].set_ylabel('Linear', fontsize=16)\n",
    "    axs[2, 0].set_ylabel('Conv', fontsize=16)\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xticks=[], yticks=[])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save (model, \"conv_vae.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "name": "density_modeling.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
