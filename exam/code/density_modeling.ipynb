{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import einops as ein\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CONV_VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=2):\n",
    "        super(CONV_VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc21 = nn.Linear(128*3*3, latent_dim)\n",
    "        self.fc22 = nn.Linear(128*3*3, latent_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128*3*3),\n",
    "            nn.ReLU(),\n",
    "            Rearrange(\"batch (a b c) -> batch a b c\", a=128, b=3, c=3),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.fc21(x), self.fc22(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, lantent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Conv2d(1, 32, 4, 2, 1)\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc1a = nn.Linear(400, 100)\n",
    "        self.fc21 = nn.Linear(100, lantent_dim)  # Latent space of 2D\n",
    "        self.fc22 = nn.Linear(100, lantent_dim)  # Latent space of 2D\n",
    "        self.fc3 = nn.Linear(lantent_dim, 100)  # Latent space of 2D\n",
    "        self.fc3a = nn.Linear(100, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc1a(h1))\n",
    "        return self.fc21(h2), self.fc22(h2)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        h4 = F.relu(self.fc3a(h3))\n",
    "        return torch.sigmoid(self.fc4(h4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "    def loss(self, recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = CONV_VAE(2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "batch_size2 = 256\n",
    "log_interval2 = 10\n",
    "epochs2 = 100\n",
    "\n",
    "# torch.manual_seed(1) # args.seed\n",
    "\n",
    "kwargs = {'num_workers': 4,\n",
    "          'pin_memory': True} if device == \"cuda\" else {}  # args.cuda\n",
    "\n",
    "# Get train and train data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size2, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size2, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    # so that everything has gradients and we can do backprop and so on...\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()  # \"reset\" gradients to 0 for text iteration\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = model.loss(recon_batch, data, mu, logvar)\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()  # backpropagation\n",
    "    train_losses.append(train_loss / len(train_loader.dataset))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # no_grad turns of gradients...\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += model.loss(recon_batch, data, mu, logvar).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs2 + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(latent_dims):\n",
    "    global model\n",
    "    global optimizer\n",
    "    global train_losses\n",
    "    global test_losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_res = []\n",
    "    test_res = []\n",
    "\n",
    "    for l in latent_dims:\n",
    "        model = VAE(l).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "        for epoch in range(1, 101):\n",
    "            train(epoch)\n",
    "            test(epoch)\n",
    "        train_res.append(train_losses)\n",
    "        test_res.append(test_losses)\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "\n",
    "    for i, train_loss in enumerate(train_res):\n",
    "        f1 = open(f\"{latent_dims[i]}test.txt\", \"w\")\n",
    "        f1.write(f\"{test_res[i]}\")\n",
    "        f2 = open(f\"{latent_dims[i]}train.txt\", \"w\")\n",
    "        f2.write(f\"{train_loss}\")\n",
    "\n",
    "\n",
    "train_models([2, 4, 8, 16, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def read_array(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        array = f.read()\n",
    "    array = array.replace('[', '')\n",
    "    array = array.replace(']', '')\n",
    "    array = array.replace(' ', '')\n",
    "    array = array.split(',')\n",
    "    array = [float(i) for i in array]\n",
    "\n",
    "    # Remove first element for better visualization\n",
    "    array = array[1:]\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "folder1 = 'results-lin/'\n",
    "folder2 = 'results-conv/'\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax1.plot(read_array(folder1 + '2test.txt'), label='linear 2')\n",
    "ax1.plot(read_array(folder2 + '2test.txt'), label='conv 2')\n",
    "ax1.plot(read_array(folder1 + '4test.txt'), label='linear 4')\n",
    "ax1.plot(read_array(folder2 + '4test.txt'), label='conv 4')\n",
    "ax1.set_title('Latent dimension 2 and 4')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Test loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(read_array(folder1 + '8test.txt'), label='linear 8')\n",
    "ax2.plot(read_array(folder2 + '8test.txt'), label='conv 8')\n",
    "ax2.plot(read_array(folder1 + '16test.txt'), label='linear 16')\n",
    "ax2.plot(read_array(folder2 + '16test.txt'), label='conv 16')\n",
    "ax2.set_title('Latent dimension 8 and 16')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Test loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torch.load('models/conv_vae16.pth', map_location=device)\n",
    "model_lin = torch.load('models/lin_vae16.pth', map_location=device)\n",
    "\n",
    "# Visualize reconstructions of five images from the test set\n",
    "with torch.no_grad():\n",
    "    sample = next(iter(test_loader))[0].to(device)\n",
    "    recon_lin, _, _ = model_lin(sample.view(-1, 784))\n",
    "    recon_conv, _, _ = model_conv(sample)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 5, figsize=(10, 6))\n",
    "    for i in range(5):\n",
    "        axs[0, i].imshow(sample[i].cpu().view(28, 28), cmap='gray')\n",
    "        axs[1, i].imshow(recon_lin[i].cpu().view(28, 28), cmap='gray')\n",
    "        axs[2, i].imshow(recon_conv[i].cpu().view(28, 28), cmap='gray')\n",
    "\n",
    "    axs[0, 0].set_ylabel('Original', fontsize=16)\n",
    "    axs[1, 0].set_ylabel('Linear', fontsize=16)\n",
    "    axs[2, 0].set_ylabel('Conv', fontsize=16)\n",
    "\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xticks=[], yticks=[])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 16 from latent space\n",
    "import matplotlib.pyplot as plt\n",
    "imgs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(16):\n",
    "        sample = torch.randn(1, 2).to(device)\n",
    "        sample = model.decode(sample).cpu()\n",
    "        imgs.append(sample.view(1, 1, 28, 28))\n",
    "\n",
    "# Plot images\n",
    "fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(imgs[i * 4 + j][0, 0, :, :], cmap=\"gray\")\n",
    "        axs[i, j].axis(\"off\")\n",
    "\n",
    "# Remove whitespace between subplots\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('vae_sample.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 50 images from latent space\n",
    "model_conv = torch.load('models/conv_vae16.pth', map_location=device)\n",
    "imgs = []\n",
    "with torch.no_grad():\n",
    "    for i in range(50):\n",
    "        sample = torch.randn(1, 16).to(device)\n",
    "        sample = model_conv.decode(sample).cpu()\n",
    "        imgs.append(sample.view(1, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "import torch\n",
    "_ = torch.manual_seed(123)\n",
    "fid = FrechetInceptionDistance(feature=64)\n",
    "\n",
    "new_imgs = torch.zeros(50, 3, 28, 28).to(torch.uint8)\n",
    "\n",
    "# Sample 50 images\n",
    "for i in range(50):\n",
    "    img = imgs[i]\n",
    "    img = (img * 255).to(torch.uint8)\n",
    "    img = img.reshape(1, 1, 28, 28)\n",
    "    img = img.repeat(1, 3, 1, 1)\n",
    "    new_imgs[i] = img\n",
    "\n",
    "fid.update(new_imgs, False)\n",
    "\n",
    "# Apply fid.update to entire test set\n",
    "for i, (data, _) in enumerate(test_loader):\n",
    "    data = data.to(device)\n",
    "    data = (data * 255).to(torch.uint8)\n",
    "    data = data.repeat(1, 3, 1, 1)\n",
    "    fid.update(data, True)\n",
    "\n",
    "fid.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"conv_vae.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "name": "density_modeling.ipynb",
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
